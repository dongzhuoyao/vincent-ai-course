<!DOCTYPE HTML>
<html lang="cn" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Vincent教你学AI </title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="preface.html">Preface</a></li><li class="chapter-item expanded "><a href="diffusion.html"><strong aria-hidden="true">1.</strong> Diffusion Model</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="diffusion/ddpm.html"><strong aria-hidden="true">1.1.</strong> DDPM</a></li><li class="chapter-item expanded "><a href="diffusion/stable-diffusion.html"><strong aria-hidden="true">1.2.</strong> Stable Diffusion</a></li><li class="chapter-item expanded "><a href="diffusion/consistency.html"><strong aria-hidden="true">1.3.</strong> Consistency Models</a></li><li class="chapter-item expanded "><a href="diffusion/backbone.html"><strong aria-hidden="true">1.4.</strong> 骨干网络设计</a></li></ol></li><li class="chapter-item expanded "><a href="normalizing-flow.html"><strong aria-hidden="true">2.</strong> Normalizing Flow</a></li><li class="chapter-item expanded "><a href="flow-matching.html"><strong aria-hidden="true">3.</strong> Flow Matching</a></li><li class="chapter-item expanded "><a href="vae.html"><strong aria-hidden="true">4.</strong> Variational Autoencoder (VAE)</a></li><li class="chapter-item expanded "><a href="gan.html"><strong aria-hidden="true">5.</strong> Generative Adversarial Network (GAN)</a></li><li class="chapter-item expanded "><a href="auto-regressive.html"><strong aria-hidden="true">6.</strong> Auto-regressive Model</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Vincent教你学AI </h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="前言"><a class="header" href="#前言">前言</a></h1>
<p>欢迎阅读生成式AI模型指南。本教程为中国研究人员提供了一个全面的资源，以了解近年来革新人工智能领域的各种生成式AI模型。</p>
<h2 id="本教程的目的"><a class="header" href="#本教程的目的">本教程的目的</a></h2>
<p>本指南旨在提供对关键生成式AI模型的清晰而简明的概述，重点关注：</p>
<ul>
<li><strong>扩散模型</strong>：包括DDPM、Stable Diffusion和一致性模型</li>
<li><strong>标准化流</strong>：使用可逆变换的模型</li>
<li><strong>流匹配</strong>：基于连续时间流的生成模型</li>
<li><strong>变分自编码器(VAE)</strong>：具有概率编码器和解码器的潜变量模型</li>
<li><strong>生成对抗网络(GAN)</strong>：具有生成器和判别器网络的对抗框架</li>
<li><strong>自回归模型</strong>：如用于大型语言模型的Transformer架构</li>
</ul>
<p>每个部分都探讨了这些模型的理论基础、架构和实际应用，使不同技术专业水平的读者都能理解复杂的概念。</p>
<h2 id="如何使用本指南"><a class="header" href="#如何使用本指南">如何使用本指南</a></h2>
<p>本书的结构允许顺序阅读和针对特定模型的探索。您可以：</p>
<ol>
<li>按顺序阅读各章节，全面了解生成模型的全景</li>
<li>直接跳到您感兴趣的特定模型类型</li>
<li>使用参考部分查找原始论文和其他资源</li>
</ol>
<p>我们希望本指南能增强您对生成式AI的理解，并在这一激动人心的领域中启发您自己的实验和应用。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩散模型"><a class="header" href="#扩散模型">扩散模型</a></h1>
<p>扩散模型是一类已经彻底改变了基于AI的内容创作的生成模型。这些模型通过逐渐向数据添加噪声，然后学习逆转这一过程来生成新样本。</p>
<h2 id="概述"><a class="header" href="#概述">概述</a></h2>
<p>扩散模型已成为生成式AI中最强大的方法之一，特别是对于图像，但也越来越多地应用于音频、视频和3D内容等其他模态。它们的工作原理是：</p>
<ol>
<li>前向过程：逐渐向数据添加噪声，直到变成纯噪声</li>
<li>反向过程：学习迭代去噪以生成新数据</li>
</ol>
<h2 id="主要优势"><a class="header" href="#主要优势">主要优势</a></h2>
<ul>
<li>高质量生成</li>
<li>灵活的条件机制</li>
<li>与GANs相比训练更稳定</li>
<li>强大的理论基础</li>
</ul>
<h2 id="扩散模型的类型"><a class="header" href="#扩散模型的类型">扩散模型的类型</a></h2>
<p>本节介绍扩散模型的几个重要变体：</p>
<ul>
<li><a href="./diffusion/ddpm.html">DDPM</a>：原始的去噪扩散概率模型</li>
<li><a href="./diffusion/stable-diffusion.html">Stable Diffusion</a>：用于文本到图像生成的潜在扩散模型</li>
<li><a href="./diffusion/consistency.html">一致性模型</a>：快速采样扩散变体</li>
</ul>
<p>每个子章节都提供了关于模型架构、训练过程和应用的详细解释。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="去噪扩散概率模型-ddpm"><a class="header" href="#去噪扩散概率模型-ddpm">去噪扩散概率模型 (DDPM)</a></h1>
<p>去噪扩散概率模型(DDPM)是一类通过逆转渐进噪声过程来学习生成数据的生成模型。</p>
<h2 id="关键概念"><a class="header" href="#关键概念">关键概念</a></h2>
<ul>
<li>前向扩散过程：逐渐向数据添加高斯噪声</li>
<li>反向扩散过程：学习逐步对图像去噪</li>
<li>U-Net架构：常用作去噪网络</li>
</ul>
<h2 id="数学公式"><a class="header" href="#数学公式">数学公式</a></h2>
<p>DDPM通过定义一个逐渐向数据添加噪声直至变成纯噪声的前向扩散过程，然后训练模型来逆转这一过程。</p>
<h2 id="参考文献"><a class="header" href="#参考文献">参考文献</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2006.11239">Ho et al. (2020), "去噪扩散概率模型"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stable-diffusion-稳定扩散模型"><a class="header" href="#stable-diffusion-稳定扩散模型">Stable Diffusion 稳定扩散模型</a></h1>
<p>Stable Diffusion是由Stability AI开发的潜在扩散模型，能够根据文本描述生成详细的图像。</p>
<h2 id="架构"><a class="header" href="#架构">架构</a></h2>
<ul>
<li>潜在空间扩散：在压缩的潜在空间中应用扩散过程</li>
<li>文本条件：使用CLIP文本嵌入来引导生成过程</li>
<li>VAE：将图像编码到潜在空间并解码回来</li>
<li>UNet：在潜在空间中执行去噪过程</li>
</ul>
<h2 id="主要特点"><a class="header" href="#主要特点">主要特点</a></h2>
<ul>
<li>文本到图像生成</li>
<li>图像到图像转换</li>
<li>图像修复和扩展</li>
<li>微调能力</li>
</ul>
<h2 id="应用"><a class="header" href="#应用">应用</a></h2>
<ul>
<li>创意艺术生成</li>
<li>设计原型制作</li>
<li>内容创作</li>
<li>图像编辑</li>
</ul>
<h2 id="参考文献-1"><a class="header" href="#参考文献-1">参考文献</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2112.10752">Rombach et al. (2022), "使用潜在扩散模型进行高分辨率图像合成"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="consistency-models"><a class="header" href="#consistency-models">Consistency Models</a></h1>
<p>Consistency Models are a type of generative model that offers faster sampling than traditional diffusion models while maintaining generation quality.</p>
<h2 id="key-innovations"><a class="header" href="#key-innovations">Key Innovations</a></h2>
<ul>
<li>Single-step generation: can generate high-quality samples in just one step</li>
<li>Few-step generation: offers quality-speed trade-off with few sampling steps</li>
<li>Distillation approach: distills knowledge from a pre-trained diffusion model</li>
</ul>
<h2 id="advantages"><a class="header" href="#advantages">Advantages</a></h2>
<ul>
<li>Much faster sampling than regular diffusion models</li>
<li>Deterministic sampling process</li>
<li>Maintains generation quality comparable to diffusion models</li>
</ul>
<h2 id="technical-details"><a class="header" href="#technical-details">Technical Details</a></h2>
<ul>
<li>Consistency functions: maps noise to data points</li>
<li>Consistency distillation: training technique to learn consistency functions</li>
<li>Self-conditioning: improves generation quality</li>
</ul>
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2303.01469">Song et al. (2023), "Consistency Models"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="扩散模型骨干网络设计"><a class="header" href="#扩散模型骨干网络设计">扩散模型骨干网络设计</a></h1>
<p>扩散模型的性能在很大程度上取决于其骨干网络的设计。这些骨干网络负责学习噪声预测或去噪过程，对生成质量至关重要。</p>
<h2 id="u-net架构"><a class="header" href="#u-net架构">U-Net架构</a></h2>
<p>U-Net是扩散模型中最常用的骨干网络，其特点包括：</p>
<ul>
<li><strong>对称编码器-解码器结构</strong>：通过下采样逐步减小特征图尺寸，然后通过上采样恢复尺寸</li>
<li><strong>跳跃连接</strong>：连接编码器和解码器对应层，保留细节信息</li>
<li><strong>残差块</strong>：改进的ResNet块，提高训练稳定性和模型性能</li>
<li><strong>自注意力层</strong>：在某些分辨率层中引入，捕获远程依赖关系</li>
</ul>
<h2 id="其他常见骨干网络"><a class="header" href="#其他常见骨干网络">其他常见骨干网络</a></h2>
<h3 id="transformer架构"><a class="header" href="#transformer架构">Transformer架构</a></h3>
<ul>
<li><strong>Diffusion Transformer (DiT)</strong>：使用Transformer块替代卷积层</li>
<li><strong>U-ViT</strong>：结合U-Net的多尺度特性和Vision Transformer的注意力机制</li>
<li><strong>优势</strong>：更好地捕获全局依赖关系，对大尺寸图像效果更佳</li>
</ul>
<h3 id="高效改进"><a class="header" href="#高效改进">高效改进</a></h3>
<ul>
<li><strong>Progressive U-Net</strong>：渐进式的U-Net变体，针对不同噪声级别使用不同复杂度的网络</li>
<li><strong>轻量级设计</strong>：使用分组卷积、深度可分离卷积等减少参数量</li>
<li><strong>知识蒸馏</strong>：从大型模型蒸馏知识到小型模型，平衡效率和质量</li>
</ul>
<h2 id="时间步和条件嵌入"><a class="header" href="#时间步和条件嵌入">时间步和条件嵌入</a></h2>
<ul>
<li><strong>时间步嵌入</strong>：将去噪步骤转换为特征表示，通常使用正弦位置编码</li>
<li><strong>条件嵌入</strong>：
<ul>
<li><strong>类别条件</strong>：使用类别嵌入或one-hot向量</li>
<li><strong>文本条件</strong>：使用CLIP或T5等语言模型的文本编码</li>
<li><strong>跨模态条件</strong>：结合多种模态输入的特征</li>
</ul>
</li>
</ul>
<h2 id="扩散模型骨干设计中的关键考虑因素"><a class="header" href="#扩散模型骨干设计中的关键考虑因素">扩散模型骨干设计中的关键考虑因素</a></h2>
<ol>
<li><strong>感受野大小</strong>：更大的感受野有助于捕获全局结构</li>
<li><strong>参数效率</strong>：优化参数数量和计算复杂度</li>
<li><strong>多分辨率处理</strong>：有效处理不同尺度的特征</li>
<li><strong>注意力机制</strong>：在合适的层级高效应用注意力机制</li>
<li><strong>可扩展性</strong>：能够适应不同尺寸的输入和复杂度要求</li>
</ol>
<h2 id="最新研究方向"><a class="header" href="#最新研究方向">最新研究方向</a></h2>
<ul>
<li><strong>动态架构</strong>：根据噪声水平动态调整网络结构</li>
<li><strong>混合架构</strong>：结合CNN和Transformer的优点</li>
<li><strong>一致性架构</strong>：专为一致性模型设计的特殊骨干网络</li>
<li><strong>量化感知设计</strong>：考虑到部署时量化需求的骨干网络设计</li>
</ul>
<h2 id="参考文献-2"><a class="header" href="#参考文献-2">参考文献</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1505.04597">Ronneberger et al. (2015), "U-Net: 用于生物医学图像分割的卷积网络"</a></li>
<li><a href="https://arxiv.org/abs/2006.11239">Ho et al. (2020), "去噪扩散概率模型"</a></li>
<li><a href="https://arxiv.org/abs/2212.09748">Peebles &amp; Xie (2023), "扩散变换器"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="normalizing-flow"><a class="header" href="#normalizing-flow">Normalizing Flow</a></h1>
<p>Normalizing Flows are a family of generative models that use invertible transformations to map between a simple base distribution and a complex target distribution.</p>
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<ul>
<li><strong>Invertible Transformations</strong>: Bijective mappings between spaces</li>
<li><strong>Change of Variables Formula</strong>: Mathematical foundation that allows exact likelihood computation</li>
<li><strong>Flow-based Generation</strong>: Sampling from a simple distribution and transforming through learned flows</li>
</ul>
<h2 id="types-of-normalizing-flows"><a class="header" href="#types-of-normalizing-flows">Types of Normalizing Flows</a></h2>
<ul>
<li><strong>NICE/RealNVP</strong>: Coupling layers with affine transformations</li>
<li><strong>Glow</strong>: Extended RealNVP with 1x1 convolutions</li>
<li><strong>Autoregressive Flows (IAF, MAF)</strong>: Using autoregressive transformations</li>
<li><strong>Continuous Normalizing Flows</strong>: Defining flows using ordinary differential equations</li>
</ul>
<h2 id="advantages-1"><a class="header" href="#advantages-1">Advantages</a></h2>
<ul>
<li><strong>Exact Likelihood</strong>: Unlike VAEs, flows provide exact likelihood computation</li>
<li><strong>Efficient Sampling</strong>: Unlike autoregressive models, sampling can be parallelized</li>
<li><strong>Invertibility</strong>: Can transform in both directions (generation and inference)</li>
<li><strong>Stable Training</strong>: More stable than GANs, using maximum likelihood</li>
</ul>
<h2 id="applications"><a class="header" href="#applications">Applications</a></h2>
<ul>
<li><strong>Image Generation</strong>: High-quality image synthesis</li>
<li><strong>Anomaly Detection</strong>: Identifying outliers in data</li>
<li><strong>Density Estimation</strong>: Learning complex probability distributions</li>
<li><strong>Variational Inference</strong>: More expressive posterior approximations</li>
</ul>
<h2 id="challenges"><a class="header" href="#challenges">Challenges</a></h2>
<ul>
<li><strong>Architectural Constraints</strong>: Requiring invertibility limits model expressiveness</li>
<li><strong>Computational Cost</strong>: Some flows can be computationally expensive</li>
<li><strong>High-dimensional Data</strong>: Scaling to very high dimensions can be challenging</li>
</ul>
<h2 id="references-1"><a class="header" href="#references-1">References</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1505.05770">Rezende &amp; Mohamed (2015), "Variational Inference with Normalizing Flows"</a></li>
<li><a href="https://arxiv.org/abs/1605.08803">Dinh et al. (2016), "Density estimation using Real NVP"</a></li>
<li><a href="https://arxiv.org/abs/1807.03039">Kingma &amp; Dhariwal (2018), "Glow: Generative Flow with Invertible 1x1 Convolutions"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="flow-matching"><a class="header" href="#flow-matching">Flow Matching</a></h1>
<p>Flow Matching is a generative modeling technique that builds upon the ideas of continuous normalizing flows and probability flow ODEs, offering an alternative training approach for generative models.</p>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Flow Matching defines a continuous-time transformation from a simple distribution (like a Gaussian) to a complex target distribution. Unlike traditional normalizing flows, flow matching doesn't require computing the Jacobian determinant, making it more flexible and computationally efficient.</p>
<h2 id="key-concepts-1"><a class="header" href="#key-concepts-1">Key Concepts</a></h2>
<ul>
<li><strong>Vector Fields</strong>: Learning a vector field to represent the continuous-time flow</li>
<li><strong>Straight-line Paths</strong>: Using simple paths between distributions</li>
<li><strong>Conditional Flow Matching</strong>: Extending to conditional generation</li>
<li><strong>ODE-based Generation</strong>: Sampling by solving an ordinary differential equation</li>
</ul>
<h2 id="relation-to-other-models"><a class="header" href="#relation-to-other-models">Relation to Other Models</a></h2>
<ul>
<li><strong>Diffusion Models</strong>: Flow matching can be seen as a generalization of score-based diffusion models</li>
<li><strong>Normalizing Flows</strong>: Similar concept but with different training objectives</li>
<li><strong>Optimal Transport</strong>: Connection to optimal transport theory</li>
</ul>
<h2 id="advantages-2"><a class="header" href="#advantages-2">Advantages</a></h2>
<ul>
<li><strong>Flexible Architecture</strong>: No invertibility requirement</li>
<li><strong>Efficient Training</strong>: More efficient than score matching in some cases</li>
<li><strong>Theoretical Guarantees</strong>: Well-founded mathematical framework</li>
<li><strong>Stable Training</strong>: Often more stable than adversarial approaches</li>
</ul>
<h2 id="applications-1"><a class="header" href="#applications-1">Applications</a></h2>
<ul>
<li><strong>Image Generation</strong>: Creating realistic images</li>
<li><strong>Shape Generation</strong>: 3D shape synthesis</li>
<li><strong>Audio Synthesis</strong>: Generating audio waveforms</li>
<li><strong>Density Estimation</strong>: Learning complex distributions</li>
</ul>
<h2 id="references-2"><a class="header" href="#references-2">References</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/2210.02747">Lipman et al. (2022), "Flow Matching for Generative Modeling"</a></li>
<li><a href="https://arxiv.org/abs/2209.03003">Liu et al. (2022), "Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow"</a></li>
<li><a href="https://arxiv.org/abs/2302.00482">Tong et al. (2023), "Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="变分自编码器-vae"><a class="header" href="#变分自编码器-vae">变分自编码器 (VAE)</a></h1>
<p>变分自编码器(VAE)是一类将神经网络与变分推断相结合来学习数据潜在表示的生成模型。</p>
<h2 id="架构-1"><a class="header" href="#架构-1">架构</a></h2>
<p>VAE由两个主要组件组成：</p>
<ul>
<li><strong>编码器网络</strong>：将输入数据映射到潜在空间中的分布</li>
<li><strong>解码器网络</strong>：将潜在空间中的点映射回数据空间</li>
</ul>
<h2 id="数学框架"><a class="header" href="#数学框架">数学框架</a></h2>
<ul>
<li><strong>变分推断</strong>：近似不可处理的后验分布</li>
<li><strong>证据下界(ELBO)</strong>：结合重建和正则化的目标函数</li>
<li><strong>重参数化技巧</strong>：使得反向传播可以通过采样过程进行</li>
</ul>
<h2 id="主要变体"><a class="header" href="#主要变体">主要变体</a></h2>
<ul>
<li><strong>β-VAE</strong>：为KL散度项引入权重因子</li>
<li><strong>条件VAE</strong>：将条件信息纳入生成过程</li>
<li><strong>VQ-VAE</strong>：在潜在空间中使用向量量化</li>
<li><strong>层次VAE</strong>：采用多层潜变量</li>
</ul>
<h2 id="优势"><a class="header" href="#优势">优势</a></h2>
<ul>
<li><strong>结构化潜在空间</strong>：创建连续且有意义的潜在空间</li>
<li><strong>生成能力</strong>：能够从学习的分布中生成新样本</li>
<li><strong>无监督学习</strong>：不需要标记数据</li>
<li><strong>概率框架</strong>：提供不确定性估计</li>
</ul>
<h2 id="局限性"><a class="header" href="#局限性">局限性</a></h2>
<ul>
<li><strong>模糊输出</strong>：通常比GANs产生更模糊的结果</li>
<li><strong>后验崩塌</strong>：可能忽略一些潜变量</li>
<li><strong>近似差距</strong>：真实后验和近似后验可能有显著差异</li>
</ul>
<h2 id="应用-1"><a class="header" href="#应用-1">应用</a></h2>
<ul>
<li><strong>图像生成</strong>：创建新的真实图像</li>
<li><strong>表示学习</strong>：寻找有意义的数据表示</li>
<li><strong>异常检测</strong>：识别异常模式</li>
<li><strong>数据压缩</strong>：复杂数据的高效编码</li>
</ul>
<h2 id="参考文献-3"><a class="header" href="#参考文献-3">参考文献</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1312.6114">Kingma &amp; Welling (2014), "自编码变分贝叶斯"</a></li>
<li><a href="https://arxiv.org/abs/1401.4082">Rezende et al. (2014), "随机反向传播与深度生成模型中的近似推断"</a></li>
<li><a href="https://openreview.net/pdf?id=Sy2fzU9gl">Higgins et al. (2017), "beta-VAE: 使用约束变分框架学习基本视觉概念"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="generative-adversarial-network-gan"><a class="header" href="#generative-adversarial-network-gan">Generative Adversarial Network (GAN)</a></h1>
<p>Generative Adversarial Networks (GANs) are a framework for training generative models through an adversarial process involving two neural networks - a generator and a discriminator.</p>
<h2 id="core-architecture"><a class="header" href="#core-architecture">Core Architecture</a></h2>
<ul>
<li><strong>Generator Network</strong>: Creates synthetic data samples from random noise</li>
<li><strong>Discriminator Network</strong>: Attempts to distinguish between real and generated samples</li>
<li><strong>Adversarial Training</strong>: The two networks are trained in a competitive minimax game</li>
</ul>
<h2 id="mathematical-framework"><a class="header" href="#mathematical-framework">Mathematical Framework</a></h2>
<ul>
<li><strong>Minimax Game</strong>: Formulation as a two-player zero-sum game</li>
<li><strong>Nash Equilibrium</strong>: Theoretical solution point where neither network can improve</li>
<li><strong>Non-saturating Loss</strong>: Modified objective to prevent generator gradient vanishing</li>
</ul>
<h2 id="key-gan-variants"><a class="header" href="#key-gan-variants">Key GAN Variants</a></h2>
<ul>
<li><strong>DCGAN</strong>: Introduces convolutional architectures for stable training</li>
<li><strong>Conditional GAN</strong>: Incorporates class or attribute information</li>
<li><strong>CycleGAN</strong>: Enables unpaired image-to-image translation</li>
<li><strong>StyleGAN</strong>: Progressive growing with style-based generator for high-quality images</li>
<li><strong>BigGAN</strong>: Scaled-up architecture for high-fidelity image generation</li>
<li><strong>WGAN</strong>: Wasserstein GAN with improved training stability</li>
</ul>
<h2 id="advantages-3"><a class="header" href="#advantages-3">Advantages</a></h2>
<ul>
<li><strong>Sharp, Realistic Outputs</strong>: Produces crisp, high-quality samples</li>
<li><strong>Implicit Density Modeling</strong>: No need to explicitly define a likelihood function</li>
<li><strong>Versatile Framework</strong>: Applicable to many data types and problems</li>
<li><strong>Strong Empirical Results</strong>: State-of-the-art in many image generation tasks</li>
</ul>
<h2 id="challenges-1"><a class="header" href="#challenges-1">Challenges</a></h2>
<ul>
<li><strong>Training Instability</strong>: Prone to mode collapse and oscillating behavior</li>
<li><strong>Evaluation Difficulty</strong>: Hard to quantitatively evaluate quality</li>
<li><strong>Lack of Inference</strong>: Standard GANs don't provide inference capabilities</li>
<li><strong>Requires Careful Tuning</strong>: Sensitive to hyperparameters and architecture choices</li>
</ul>
<h2 id="applications-2"><a class="header" href="#applications-2">Applications</a></h2>
<ul>
<li><strong>Image Generation</strong>: Creating photorealistic images</li>
<li><strong>Image Translation</strong>: Converting between image domains</li>
<li><strong>Data Augmentation</strong>: Generating synthetic training data</li>
<li><strong>Super-resolution</strong>: Enhancing low-resolution images</li>
<li><strong>Art Generation</strong>: Creating novel artistic content</li>
</ul>
<h2 id="references-3"><a class="header" href="#references-3">References</a></h2>
<ul>
<li><a href="https://arxiv.org/abs/1406.2661">Goodfellow et al. (2014), "Generative Adversarial Networks"</a></li>
<li><a href="https://arxiv.org/abs/1511.06434">Radford et al. (2015), "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks"</a></li>
<li><a href="https://arxiv.org/abs/1812.04948">Karras et al. (2019), "A Style-Based Generator Architecture for Generative Adversarial Networks"</a></li>
<li><a href="https://arxiv.org/abs/1701.07875">Arjovsky et al. (2017), "Wasserstein GAN"</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="auto-regressive-model"><a class="header" href="#auto-regressive-model">Auto-regressive Model</a></h1>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
